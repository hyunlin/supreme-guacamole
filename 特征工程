特征工程的目标在于对特征进行进一步分析，并对于数据进行处理
常见的特征工程包括：
  1. 异常处理
    通过箱线图（或 3-Sigma）分析删除异常值；
    BOX-COX 转换（处理有偏分布）；
    长尾截断；
  2. 特征归一化/标准化
    标准化（转换为标准正态分布）；
    归一化（抓换到 [0,1] 区间）；
    针对幂律分布，可以采用公式：  log((1+x)/(1+median))
  3. 数据分桶
    等频分桶；
    等距分桶；
    Best-KS 分桶（类似利用基尼指数进行二分类）；
    卡方分桶；
  4. 缺失值处理
    不处理（针对类似 XGBoost 等树模型）；
    删除（缺失数据太多）；
    插值补全，包括均值/中位数/众数/建模预测/多重插补/压缩感知补全/矩阵补全等；
    分箱，缺失值一个箱；
  5. 特征构造
    构造统计量特征，报告计数、求和、比例、标准差等；
    时间特征，包括相对时间和绝对时间，节假日，双休日等；
    地理信息，包括分箱，分布编码等方法；
    非线性变换，包括 log/ 平方/ 根号等；
    特征组合，特征交叉；
    仁者见仁，智者见智。
  6. 特征筛选
    过滤式（filter）：先对数据进行特征选择，然后在训练学习器，常见的方法有 Relief/方差选择发/相关系数法/卡方检验法/互信息法；
    包裹式（wrapper）：直接把最终将要使用的学习器的性能作为特征子集的评价准则，常见方法有 LVM（Las Vegas Wrapper） ；
    嵌入式（embedding）：结合过滤式和包裹式，学习器训练过程中自动进行了特征选择，常见的有 lasso 回归；
  7. 降维
    PCA/ LDA/ ICA；
    特征选择也是一种降维。
  
